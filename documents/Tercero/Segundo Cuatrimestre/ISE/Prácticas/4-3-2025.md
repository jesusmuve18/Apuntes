```
SERVER=localhost
TOKEN=$(curl -s\
-u etsiitApli:laApiDeLaETSIITDaLache
-d "login=mariveliss@tropoli.com@password=anim"\
-H "Content-Type

```
Muchas aplicaciones generan tokens JWT para algunas funcionalidades. En JWT debugger podemos decodificar un token JWT (está en las referencias del github).

Hay que tener en cuenta que los tokens no están cifrados por lo que no se recomienda poner información privada. Lo que sí están es firmados (para que no cualquiera pueda crear un token con el que suplantar una identidad). En este caso se usa una clave simétrica.

No tenemos que saberlo pero si queremos verificar el código de ese token, en node, tenemos config -> config.json y tenemos la firma de nuestro servidor.

BasicAuth descarta aquellos clientes de la API que no conozcan el "secreto" para evitar que atacantes puedan afectar al buen funcionamiento de nuestro servidor. 

Es importante que abramos JMeter desde el directorio en el que vamos a tener los tests (para que los paths que luego se pedirán sean correctos).

Podemos crear un test que se llame 'Prácticas ISE' y vamos a crear 2 thread groups, uno para alumnos y otro para administradores.

Creamos un HTTP Requests Defaults donde pondremos la variable `${HOST}` en el ip y `${PORT}` en el puerto. Añadimos un HTTP Authorization manager con nombre Basic Auth.

Los alumnos van a tener en primer lugar un acceso de login:
- Acción `POST /api/v1/auth/login`
- Añadimos las variables `login` y `password` con valores `${EMAIL}` Y `${PASSWORD}`. (se puede probar primero con constantes).
- Tenemos un elemento de confituración que se llama `CSV Data Set Config` en el que le podemos poner el nombre "leer credenciales Alumnos" y lo metemos dentro del grupo alumnos. Tendremos que avertiguar cómo leer el archivo que se nos da con esta herramienta.

En segundo lugar van a hacer una petición de tipo `GET /api/v1/auth/login` y añadir un post procesador (extracción de expresión regular) que cuelgue de login. Lo podemos llamar "extraer token" y con un header manager podemos ponerle "usar token" y usamos el token de cabecera requerido para extraer el token.

Vamos a repetir prácticamente la misma operación con los administradores. La principal diferencia es que el acceso de los administradores están en el archivo apiAlumnos.log. Podemos crear un Access Log Sampler para esta función (recrear el tráfico del archivo).

Finalmente tendremos que añadir algún listener para ver los resultados. Es MUY importante (va a penalizar si no se hace) que cada vez que usemos un archivo usemos paths relativos (parece ser que primero hay que seleccionar el archivo para que aparezca la ruta absoluta y después reemplazarla por la relativa poniendo un '.' en el directorio que se corresponda al de trabajo).

# Anexo

Un docker-compose nos permite crear una serie de contenedores y establecer una red de conexión entre ellos (para que puedan comunicarse). Podemos definir varias bases de datos y varios nodes, limitar los recursos, etc. La herramienta más popular hoy en día se llama "Kubermetes" o "k8s". docker-compose no se suele usar a nivel profesional pero es muy práctico para el tipo de tareas que se trabajan en la asignatura.

Si vemos el archivo docker-compose.yml podemos ver que lo único que se ha hecho ha sido levantar un contenedor con la imagen de monogo:6 (esto le dice que se baje la imagen de dockerhub con la etiqueta 6 y lo va a ejecutar), es decir `docker pull mongo:6 & docker run mongo:6`. Además se le ha asignado el puerto `27017` (el puerto estándard de mongo). Los otros dos contenedores se van a conectar a mongo (dentro del host o anfitrión). Se especifica el puerto para poder acceder desde fuera a este servicio (por ejemplo con `mongoclient localhost:27017`). Esto en verdad no se necesitaba para la API pero facilita cualquier acción de depuración. Es simplemente una publicación del puerto pero se podría haber quitado.

Cuando pone build lo que va a hacer docker-compose es construir el contenedor con el Dockerfile (como un Makefile pero para contenedores).  

---

Es muy popular para monitorizar un equipo linux usar `top`. Esto nos muestra muchas métricas que se pueden ejecutar con distintas instrucciones. Esto significa que `top` es solo un entorno de usuario. Por ejemplo el uptime se puede obtener con `uptime`. Con `loadavg` podemos ver la carga media. Los procesos se pueden consultar listando el directorio `/proc`. Con `watch -n 1` podemos pedirle q ejecute un comando cada segundo (en este caso).

Con load avg nos salen 2 parámetros, uno de 1 min, 5 min y 15 min. Para entender estos parámetros tenemos que saber cuántos cores tiene nuestro equipo. Si pone un 1 significa que la cpu se ha usado al 100%. Si pone un 2 significa que siempre se ha estado ejecutando un proceso y siempre ha habido uno en cola de ejecución. Sin embargo, si tenemos más de un core tendremos que saber que esta es la media por cada uno de los núcleos.

todos los logs del sistema se gestionan con `systemctl list-unit-files | grep systemd` y se pueden consultar en `/var/log`.

Podemos probar a hacer `tail -f messages` en un equipo y desde el mismo equipo podemos hacer `logger -t ISE "Hola mundo"`

---

# Cron

Cron es un demonio que está corriendo en el sistema (lo podemos consultar con  `ps ax | grep -i crond`). Se ejecuta con el arranque del sistema y se ejecuta en background. El fichero de configuración se encuentra en `/etc/crontab`. Este fichero no se suele modificar. Es más común que creemos nuestros propios archivos de cron y los metamos en cualquier directorio `etc/cron.*` según la periodicidad que queramos establecer. 

Podemos ejecutar `crontab -e` para crear un nuevo cron. Por ejemplo podemos añadir la entrada 
```
* * * * * * echo "Hola ISE" | logger -t ise
```
para que cada minuto se mande al log un mensaje "Hola ISE".


Para que los logs no se expandan hasta el infinito (ya que en servidores con gran carga de accesos y trabajos) existen funcionalidades como `logrotate` que no es un servicio, que se lanza por cron y lo único que hace es leer su configuración y ejecutarla. De esta forma se pueden configurar parámetros como el número máximo de archivos de logs (cuando se supere ese número se borrará el más antiguo). Estos scripts se encuentran en logrotate.d, dependiendo del servicio que ejecuta logs. El principal problema de logrotate es que necesita matar los procesos para rotar los logs. Para ello existe `rotatelogs` que no necesita matar los procesos.

journalctl nos permite ver los mensajes del sistema.